import pickle
import pandas as pd
import numpy as np
import warnings

warnings.filterwarnings('ignore')


class ChurnPredictor:
    """
    –ö–ª–∞—Å –¥–ª—è –≤–∏–∫–æ—Ä–∏—Å—Ç–∞–Ω–Ω—è –Ω–∞–≤—á–µ–Ω–æ—ó –º–æ–¥–µ–ª—ñ –ø–µ—Ä–µ–¥–±–∞—á–µ–Ω–Ω—è churn.
    –ó–∞–≤–∞–Ω—Ç–∞–∂—É—î –º–æ–¥–µ–ª—å –∑ —Ñ–∞–π–ª—É —Ç–∞ —Ä–æ–±–∏—Ç—å –ø–µ—Ä–µ–¥–±–∞—á–µ–Ω–Ω—è –¥–ª—è –Ω–æ–≤–∏—Ö –∫–æ—Ä–∏—Å—Ç—É–≤–∞—á—ñ–≤.
    """

    def __init__(self, model_path='churn_model.pkl'):
        """
        –Ü–Ω—ñ—Ü—ñ–∞–ª—ñ–∑–∞—Ü—ñ—è –ø—Ä–µ–¥–∏–∫—Ç–æ—Ä–∞

        Parameters:
        -----------
        model_path : str
            –®–ª—è—Ö –¥–æ —Ñ–∞–π–ª—É –∑–±–µ—Ä–µ–∂–µ–Ω–æ—ó –º–æ–¥–µ–ª—ñ (.pkl)
        """
        self.model_path = model_path
        self.model = None
        self.scaler = None
        self.feature_names = None
        self.feature_importance = None
        self._load_model()

    def _load_model(self):
        """–ó–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–Ω—è –º–æ–¥–µ–ª—ñ –∑ —Ñ–∞–π–ª—É"""
        try:
            with open(self.model_path, 'rb') as f:
                model_data = pickle.load(f)

            self.model = model_data['model']
            self.scaler = model_data['scaler']
            self.feature_names = model_data['feature_names']
            self.feature_importance = model_data.get('feature_importance', None)

            print(f"‚úì –ú–æ–¥–µ–ª—å —É—Å–ø—ñ—à–Ω–æ –∑–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–æ –∑ '{self.model_path}'")
            print(f"‚úì –ö—ñ–ª—å–∫—ñ—Å—Ç—å –æ–∑–Ω–∞–∫: {len(self.feature_names)}")
            print(f"‚úì –û–∑–Ω–∞–∫–∏ –º–æ–¥–µ–ª—ñ: {self.feature_names}\n")

        except FileNotFoundError:
            raise FileNotFoundError(f"–§–∞–π–ª –º–æ–¥–µ–ª—ñ '{self.model_path}' –Ω–µ –∑–Ω–∞–π–¥–µ–Ω–æ!")
        except Exception as e:
            raise Exception(f"–ü–æ–º–∏–ª–∫–∞ –ø—Ä–∏ –∑–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–Ω—ñ –º–æ–¥–µ–ª—ñ: {str(e)}")

    def predict_single(self, user_data):
        """
        –ü–µ—Ä–µ–¥–±–∞—á–µ–Ω–Ω—è –¥–ª—è –æ–¥–Ω–æ–≥–æ –∫–æ—Ä–∏—Å—Ç—É–≤–∞—á–∞

        Parameters:
        -----------
        user_data : dict
            –°–ª–æ–≤–Ω–∏–∫ –∑ –¥–∞–Ω–∏–º–∏ –∫–æ—Ä–∏—Å—Ç—É–≤–∞—á–∞. –ö–ª—é—á—ñ - –Ω–∞–∑–≤–∏ –æ–∑–Ω–∞–∫.
            –ü—Ä–∏–∫–ª–∞–¥: {'onboarding_skips': 0, 'quiz_answers': 3, ...}

        Returns:
        --------
        dict : –†–µ–∑—É–ª—å—Ç–∞—Ç –ø–µ—Ä–µ–¥–±–∞—á–µ–Ω–Ω—è –∑ –π–º–æ–≤—ñ—Ä–Ω–æ—Å—Ç—è–º–∏
        """
        # –ü–µ—Ä–µ–≤—ñ—Ä–∫–∞ –Ω–∞—è–≤–Ω–æ—Å—Ç—ñ –≤—Å—ñ—Ö –æ–∑–Ω–∞–∫
        missing_features = set(self.feature_names) - set(user_data.keys())
        if missing_features:
            raise ValueError(f"–í—ñ–¥—Å—É—Ç–Ω—ñ –æ–∑–Ω–∞–∫–∏: {missing_features}")

        # –°—Ç–≤–æ—Ä–µ–Ω–Ω—è DataFrame –∑ –ø—Ä–∞–≤–∏–ª—å–Ω–∏–º –ø–æ—Ä—è–¥–∫–æ–º –∫–æ–ª–æ–Ω–æ–∫
        user_df = pd.DataFrame([user_data])[self.feature_names]

        # –ù–æ—Ä–º–∞–ª—ñ–∑–∞—Ü—ñ—è
        user_scaled = self.scaler.transform(user_df)

        # –ü–µ—Ä–µ–¥–±–∞—á–µ–Ω–Ω—è
        prediction = self.model.predict(user_scaled)[0]
        probabilities = self.model.predict_proba(user_scaled)[0]

        result = {
            'prediction': int(prediction),
            'prediction_label': 'Churned' if prediction == 1 else 'Active',
            'churn_probability': float(probabilities[1]),
            'active_probability': float(probabilities[0]),
            'confidence': float(max(probabilities))
        }

        return result

    def predict_batch(self, users_data):
        """
        –ü–µ—Ä–µ–¥–±–∞—á–µ–Ω–Ω—è –¥–ª—è –∫—ñ–ª—å–∫–æ—Ö –∫–æ—Ä–∏—Å—Ç—É–≤–∞—á—ñ–≤

        Parameters:
        -----------
        users_data : list of dict –∞–±–æ pandas.DataFrame
            –°–ø–∏—Å–æ–∫ —Å–ª–æ–≤–Ω–∏–∫—ñ–≤ –∞–±–æ DataFrame –∑ –¥–∞–Ω–∏–º–∏ –∫–æ—Ä–∏—Å—Ç—É–≤–∞—á—ñ–≤

        Returns:
        --------
        pandas.DataFrame : DataFrame –∑ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞–º–∏ –ø–µ—Ä–µ–¥–±–∞—á–µ–Ω—å
        """
        # –ö–æ–Ω–≤–µ—Ä—Ç–∞—Ü—ñ—è —É DataFrame —è–∫—â–æ –ø–æ—Ç—Ä—ñ–±–Ω–æ
        if isinstance(users_data, list):
            users_df = pd.DataFrame(users_data)
        else:
            users_df = users_data.copy()

        # –ü–µ—Ä–µ–≤—ñ—Ä–∫–∞ –Ω–∞—è–≤–Ω–æ—Å—Ç—ñ –≤—Å—ñ—Ö –æ–∑–Ω–∞–∫
        missing_features = set(self.feature_names) - set(users_df.columns)
        if missing_features:
            raise ValueError(f"–í—ñ–¥—Å—É—Ç–Ω—ñ –æ–∑–Ω–∞–∫–∏: {missing_features}")

        # –í–∏–±—ñ—Ä –ø–æ—Ç—Ä—ñ–±–Ω–∏—Ö –∫–æ–ª–æ–Ω–æ–∫ —É –ø—Ä–∞–≤–∏–ª—å–Ω–æ–º—É –ø–æ—Ä—è–¥–∫—É
        users_df = users_df[self.feature_names]

        # –ù–æ—Ä–º–∞–ª—ñ–∑–∞—Ü—ñ—è
        users_scaled = self.scaler.transform(users_df)

        # –ü–µ—Ä–µ–¥–±–∞—á–µ–Ω–Ω—è
        predictions = self.model.predict(users_scaled)
        probabilities = self.model.predict_proba(users_scaled)

        # –§–æ—Ä–º—É–≤–∞–Ω–Ω—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ñ–≤
        results_df = pd.DataFrame({
            'prediction': predictions.astype(int),
            'prediction_label': ['Churned' if p == 1 else 'Active' for p in predictions],
            'churn_probability': probabilities[:, 1],
            'active_probability': probabilities[:, 0],
            'confidence': probabilities.max(axis=1)
        })

        return results_df

    def predict_from_csv(self, csv_path, output_path=None):
        """
        –ü–µ—Ä–µ–¥–±–∞—á–µ–Ω–Ω—è –¥–ª—è –∫–æ—Ä–∏—Å—Ç—É–≤–∞—á—ñ–≤ –∑ CSV —Ñ–∞–π–ª—É

        Parameters:
        -----------
        csv_path : str
            –®–ª—è—Ö –¥–æ CSV —Ñ–∞–π–ª—É –∑ –¥–∞–Ω–∏–º–∏ –∫–æ—Ä–∏—Å—Ç—É–≤–∞—á—ñ–≤
        output_path : str, optional
            –®–ª—è—Ö –¥–ª—è –∑–±–µ—Ä–µ–∂–µ–Ω–Ω—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ñ–≤. –Ø–∫—â–æ None, –Ω–µ –∑–±–µ—Ä—ñ–≥–∞—î.

        Returns:
        --------
        pandas.DataFrame : DataFrame –∑ –æ—Ä–∏–≥—ñ–Ω–∞–ª—å–Ω–∏–º–∏ –¥–∞–Ω–∏–º–∏ + –ø–µ—Ä–µ–¥–±–∞—á–µ–Ω–Ω—è–º–∏
        """
        # –ó–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–Ω—è –¥–∞–Ω–∏—Ö
        df = pd.read_csv(csv_path)
        print(f"‚úì –ó–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–æ {len(df)} –∫–æ—Ä–∏—Å—Ç—É–≤–∞—á—ñ–≤ –∑ '{csv_path}'")

        # –ü–µ—Ä–µ–¥–±–∞—á–µ–Ω–Ω—è
        results = self.predict_batch(df)

        # –û–±'—î–¥–Ω–∞–Ω–Ω—è –∑ –æ—Ä–∏–≥—ñ–Ω–∞–ª—å–Ω–∏–º–∏ –¥–∞–Ω–∏–º–∏
        df_with_predictions = pd.concat([df, results], axis=1)

        # –ó–±–µ—Ä–µ–∂–µ–Ω–Ω—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ñ–≤
        if output_path:
            df_with_predictions.to_csv(output_path, index=False)
            print(f"‚úì –†–µ–∑—É–ª—å—Ç–∞—Ç–∏ –∑–±–µ—Ä–µ–∂–µ–Ω–æ —É '{output_path}'")

        # –í–∏–≤–µ–¥–µ–Ω–Ω—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏
        churn_count = (results['prediction'] == 1).sum()
        churn_pct = (churn_count / len(results)) * 100
        print(f"\nüìä –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–µ—Ä–µ–¥–±–∞—á–µ–Ω—å:")
        print(f"   Active –∫–æ—Ä–∏—Å—Ç—É–≤–∞—á—ñ–≤:  {len(results) - churn_count} ({100 - churn_pct:.1f}%)")
        print(f"   Churned –∫–æ—Ä–∏—Å—Ç—É–≤–∞—á—ñ–≤: {churn_count} ({churn_pct:.1f}%)")
        print(f"   –°–µ—Ä–µ–¥–Ω—è –π–º–æ–≤—ñ—Ä–Ω—ñ—Å—Ç—å churn: {results['churn_probability'].mean():.2%}")

        return df_with_predictions

    def get_feature_importance(self, top_n=10):
        """
        –û—Ç—Ä–∏–º–∞–Ω–Ω—è –Ω–∞–π–≤–∞–∂–ª–∏–≤—ñ—à–∏—Ö –æ–∑–Ω–∞–∫

        Parameters:
        -----------
        top_n : int
            –ö—ñ–ª—å–∫—ñ—Å—Ç—å —Ç–æ–ø-–æ–∑–Ω–∞–∫ –¥–ª—è –≤–∏–≤–µ–¥–µ–Ω–Ω—è

        Returns:
        --------
        pandas.DataFrame : DataFrame –∑ –≤–∞–∂–ª–∏–≤—ñ—Å—Ç—é –æ–∑–Ω–∞–∫
        """
        if self.feature_importance is not None:
            return self.feature_importance.head(top_n)
        else:
            # –Ø–∫—â–æ feature_importance –Ω–µ –∑–±–µ—Ä–µ–∂–µ–Ω–æ, –≤–∏—Ç—è–≥—É—î–º–æ –∑ –º–æ–¥–µ–ª—ñ
            importance_df = pd.DataFrame({
                'feature': self.feature_names,
                'coefficient': self.model.coef_[0]
            }).sort_values('coefficient', key=abs, ascending=False)
            return importance_df.head(top_n)

    def explain_prediction(self, user_data, top_n=5):
        """
        –ü–æ—è—Å–Ω–µ–Ω–Ω—è –ø–µ—Ä–µ–¥–±–∞—á–µ–Ω–Ω—è –¥–ª—è –∫–æ—Ä–∏—Å—Ç—É–≤–∞—á–∞

        Parameters:
        -----------
        user_data : dict
            –°–ª–æ–≤–Ω–∏–∫ –∑ –¥–∞–Ω–∏–º–∏ –∫–æ—Ä–∏—Å—Ç—É–≤–∞—á–∞
        top_n : int
            –ö—ñ–ª—å–∫—ñ—Å—Ç—å —Ç–æ–ø-—Ñ–∞–∫—Ç–æ—Ä—ñ–≤ –¥–ª—è –ø–æ—è—Å–Ω–µ–Ω–Ω—è

        Returns:
        --------
        dict : –†–µ–∑—É–ª—å—Ç–∞—Ç –∑ –ø–æ—è—Å–Ω–µ–Ω–Ω—è–º
        """
        # –û—Ç—Ä–∏–º–∞–Ω–Ω—è –ø–µ—Ä–µ–¥–±–∞—á–µ–Ω–Ω—è
        result = self.predict_single(user_data)

        # –°—Ç–≤–æ—Ä–µ–Ω–Ω—è DataFrame –¥–ª—è –∫–æ—Ä–∏—Å—Ç—É–≤–∞—á–∞
        user_df = pd.DataFrame([user_data])[self.feature_names]
        user_scaled = self.scaler.transform(user_df)

        # –û–±—á–∏—Å–ª–µ–Ω–Ω—è –≤–Ω–µ—Å–∫—É –∫–æ–∂–Ω–æ—ó –æ–∑–Ω–∞–∫–∏
        contributions = user_scaled[0] * self.model.coef_[0]

        # –°–æ—Ä—Ç—É–≤–∞–Ω–Ω—è –∑–∞ –∞–±—Å–æ–ª—é—Ç–Ω–∏–º –∑–Ω–∞—á–µ–Ω–Ω—è–º
        contrib_df = pd.DataFrame({
            'feature': self.feature_names,
            'value': [user_data[f] for f in self.feature_names],
            'contribution': contributions
        }).sort_values('contribution', key=abs, ascending=False)

        # –¢–æ–ø-—Ñ–∞–∫—Ç–æ—Ä–∏ —â–æ –ø—ñ–¥–≤–∏—â—É—é—Ç—å —Ä–∏–∑–∏–∫ churn
        top_churn_factors = contrib_df[contrib_df['contribution'] > 0].head(top_n)

        # –¢–æ–ø-—Ñ–∞–∫—Ç–æ—Ä–∏ —â–æ –∑–Ω–∏–∂—É—é—Ç—å —Ä–∏–∑–∏–∫ churn
        top_active_factors = contrib_df[contrib_df['contribution'] < 0].head(top_n)

        result['top_churn_factors'] = top_churn_factors.to_dict('records')
        result['top_active_factors'] = top_active_factors.to_dict('records')

        return result

    def print_prediction(self, result):
        """–ö—Ä–∞—Å–∏–≤–µ –≤–∏–≤–µ–¥–µ–Ω–Ω—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç—É –ø–µ—Ä–µ–¥–±–∞—á–µ–Ω–Ω—è"""
        print("\n" + "=" * 60)
        print("üìä –†–ï–ó–£–õ–¨–¢–ê–¢ –ü–ï–†–ï–î–ë–ê–ß–ï–ù–ù–Ø")
        print("=" * 60)
        print(f"\nüéØ –ü–µ—Ä–µ–¥–±–∞—á–µ–Ω–Ω—è: {result['prediction_label']}")
        print(f"   –ô–º–æ–≤—ñ—Ä–Ω—ñ—Å—Ç—å churn:      {result['churn_probability']:.2%}")
        print(f"   –ô–º–æ–≤—ñ—Ä–Ω—ñ—Å—Ç—å –∞–∫—Ç–∏–≤–Ω–æ—Å—Ç—ñ: {result['active_probability']:.2%}")
        print(f"   –í–ø–µ–≤–Ω–µ–Ω—ñ—Å—Ç—å –º–æ–¥–µ–ª—ñ:     {result['confidence']:.2%}")

        if 'top_churn_factors' in result:
            print(f"\nüî¥ –¢–æ–ø-—Ñ–∞–∫—Ç–æ—Ä–∏ —Ä–∏–∑–∏–∫—É churn:")
            for i, factor in enumerate(result['top_churn_factors'], 1):
                print(f"   {i}. {factor['feature']}: {factor['value']:.2f} "
                      f"(–≤–Ω–µ—Å–æ–∫: {factor['contribution']:.4f})")

            print(f"\nüü¢ –¢–æ–ø-—Ñ–∞–∫—Ç–æ—Ä–∏ —É—Ç—Ä–∏–º–∞–Ω–Ω—è:")
            for i, factor in enumerate(result['top_active_factors'], 1):
                print(f"   {i}. {factor['feature']}: {factor['value']:.2f} "
                      f"(–≤–Ω–µ—Å–æ–∫: {factor['contribution']:.4f})")

        print("=" * 60 + "\n")


# ============================================================================
# –ü–†–ò–ö–õ–ê–î–ò –í–ò–ö–û–†–ò–°–¢–ê–ù–ù–Ø
# ============================================================================

def example_single_prediction():
    """–ü—Ä–∏–∫–ª–∞–¥ 1: –ü–µ—Ä–µ–¥–±–∞—á–µ–Ω–Ω—è –¥–ª—è –æ–¥–Ω–æ–≥–æ –∫–æ—Ä–∏—Å—Ç—É–≤–∞—á–∞"""
    print("\n" + "=" * 70)
    print("–ü–†–ò–ö–õ–ê–î 1: –ü–µ—Ä–µ–¥–±–∞—á–µ–Ω–Ω—è –¥–ª—è –æ–¥–Ω–æ–≥–æ –∫–æ—Ä–∏—Å—Ç—É–≤–∞—á–∞")
    print("=" * 70 + "\n")

    # –ó–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–Ω—è –º–æ–¥–µ–ª—ñ
    predictor = ChurnPredictor('churn_model.pkl')

    # –î–∞–Ω—ñ –∫–æ—Ä–∏—Å—Ç—É–≤–∞—á–∞ (–ø—Ä–∏–∫–ª–∞–¥)
    user = {
        'onboarding_skips': 0.0,
        'quiz_answers': 3.0,
        'total_events': 60.0,
        'avg_event_interval_sec': 211.58,
        'chat_opens': 4.0,
        'chat_views': 4.0,
        'messages_sent': 15.0,
        'messages_received': 8.0,
        'answer_errors': 7.0,
        'likes': 1.0,
        'dislikes': 3.0,
        'model_changes': 1.0,
        'successful_purchase': 1.0,
        'time_to_first_message_sec': 343.0,
        'error_rate': 0.467,
        'goals_creative': 0,
        'goals_professional': 0,
        'goals_personal_dev': 0,
        'goals_social_entertain': 1,
        'assist_detailed': 1,
        'assist_concise': 0,
        'interest_creative_arts': 1,
        'interest_practical': 1,
        'interest_outdoor': 0,
        'interest_intellectual': 1,
        'interest_business_tech': 0,
        'interest_lifestyle': 0
    }

    # –ü—Ä–æ—Å—Ç–µ –ø–µ—Ä–µ–¥–±–∞—á–µ–Ω–Ω—è
    result = predictor.predict_single(user)
    predictor.print_prediction(result)

    # –ü–µ—Ä–µ–¥–±–∞—á–µ–Ω–Ω—è –∑ –ø–æ—è—Å–Ω–µ–Ω–Ω—è–º
    print("\nüìã –î–µ—Ç–∞–ª—å–Ω–µ –ø–æ—è—Å–Ω–µ–Ω–Ω—è:")
    result_with_explanation = predictor.explain_prediction(user, top_n=5)
    predictor.print_prediction(result_with_explanation)


def example_batch_prediction():
    """–ü—Ä–∏–∫–ª–∞–¥ 2: –ü–µ—Ä–µ–¥–±–∞—á–µ–Ω–Ω—è –¥–ª—è –∫—ñ–ª—å–∫–æ—Ö –∫–æ—Ä–∏—Å—Ç—É–≤–∞—á—ñ–≤"""
    print("\n" + "=" * 70)
    print("–ü–†–ò–ö–õ–ê–î 2: –ü–∞–∫–µ—Ç–Ω–µ –ø–µ—Ä–µ–¥–±–∞—á–µ–Ω–Ω—è")
    print("=" * 70 + "\n")

    # –ó–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–Ω—è –º–æ–¥–µ–ª—ñ
    predictor = ChurnPredictor('churn_model.pkl')

    # –°–ø–∏—Å–æ–∫ –∫–æ—Ä–∏—Å—Ç—É–≤–∞—á—ñ–≤
    users = [
        {
            'onboarding_skips': 0.0, 'quiz_answers': 3.0, 'total_events': 60.0,
            'avg_event_interval_sec': 211.58, 'chat_opens': 4.0, 'chat_views': 4.0,
            'messages_sent': 15.0, 'messages_received': 8.0, 'answer_errors': 7.0,
            'likes': 1.0, 'dislikes': 3.0, 'successful_purchase': 1.0,
            'time_to_first_message_sec': 343.0, 'error_rate': 0.467,
            'goals_creative': 0, 'goals_professional': 0, 'goals_personal_dev': 0,
            'goals_social_entertain': 1, 'assist_detailed': 1, 'assist_concise': 0,
            'interest_creative_arts': 1, 'interest_practical': 1, 'interest_outdoor': 0,
            'interest_intellectual': 1, 'interest_business_tech': 0, 'interest_lifestyle': 0
        },
        {
            'onboarding_skips': 2.0, 'quiz_answers': 2.0, 'total_events': 73.0,
            'avg_event_interval_sec': 109.19, 'chat_opens': 3.0, 'chat_views': 3.0,
            'messages_sent': 20.0, 'messages_received': 18.0, 'answer_errors': 1.0,
            'likes': 6.0, 'dislikes': 3.0, 'successful_purchase': 1.0,
            'time_to_first_message_sec': 380.0, 'error_rate': 0.05,
            'goals_creative': 1, 'goals_professional': 1, 'goals_personal_dev': 1,
            'goals_social_entertain': 0, 'assist_detailed': 1, 'assist_concise': 0,
            'interest_creative_arts': 0, 'interest_practical': 0, 'interest_outdoor': 0,
            'interest_intellectual': 0, 'interest_business_tech': 0, 'interest_lifestyle': 0
        }
    ]

    # –ü–∞–∫–µ—Ç–Ω–µ –ø–µ—Ä–µ–¥–±–∞—á–µ–Ω–Ω—è
    results = predictor.predict_batch(users)
    print("–†–µ–∑—É–ª—å—Ç–∞—Ç–∏ –ø–∞–∫–µ—Ç–Ω–æ–≥–æ –ø–µ—Ä–µ–¥–±–∞—á–µ–Ω–Ω—è:")
    print(results)
    print()


def example_csv_prediction():
    """–ü—Ä–∏–∫–ª–∞–¥ 3: –ü–µ—Ä–µ–¥–±–∞—á–µ–Ω–Ω—è –∑ CSV —Ñ–∞–π–ª—É"""
    print("\n" + "=" * 70)
    print("–ü–†–ò–ö–õ–ê–î 3: –ü–µ—Ä–µ–¥–±–∞—á–µ–Ω–Ω—è –∑ CSV —Ñ–∞–π–ª—É")
    print("=" * 70 + "\n")

    # –ó–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–Ω—è –º–æ–¥–µ–ª—ñ
    predictor = ChurnPredictor('churn_model.pkl')

    # –ü–µ—Ä–µ–¥–±–∞—á–µ–Ω–Ω—è –¥–ª—è –≤—Å—ñ—Ö –∫–æ—Ä–∏—Å—Ç—É–≤–∞—á—ñ–≤ –∑ —Ñ–∞–π–ª—É
    results = predictor.predict_from_csv(
        csv_path='user_features.csv',
        output_path='predictions_output.csv'
    )

    # –í–∏–≤–µ–¥–µ–Ω–Ω—è –ø–µ—Ä—à–∏—Ö 10 —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ñ–≤
    print("\nüìã –ü–µ—Ä—à—ñ 10 —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ñ–≤:")
    print(results[['prediction_label', 'churn_probability', 'confidence']].head(10))

    # –ö–æ—Ä–∏—Å—Ç—É–≤–∞—á—ñ –∑ –≤–∏—Å–æ–∫–∏–º —Ä–∏–∑–∏–∫–æ–º churn
    high_risk = results[results['churn_probability'] > 0.7].sort_values(
        'churn_probability', ascending=False
    )

    print(f"\n‚ö†Ô∏è  –ö–æ—Ä–∏—Å—Ç—É–≤–∞—á—ñ –∑ –≤–∏—Å–æ–∫–∏–º —Ä–∏–∑–∏–∫–æ–º churn (>70%): {len(high_risk)}")
    if len(high_risk) > 0:
        print(high_risk[['prediction_label', 'churn_probability']].head(5))


def example_feature_importance():
    """–ü—Ä–∏–∫–ª–∞–¥ 4: –ü–µ—Ä–µ–≥–ª—è–¥ –≤–∞–∂–ª–∏–≤–æ—Å—Ç—ñ –æ–∑–Ω–∞–∫"""
    print("\n" + "=" * 70)
    print("–ü–†–ò–ö–õ–ê–î 4: –ù–∞–π–≤–∞–∂–ª–∏–≤—ñ—à—ñ –æ–∑–Ω–∞–∫–∏")
    print("=" * 70 + "\n")

    # –ó–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–Ω—è –º–æ–¥–µ–ª—ñ
    predictor = ChurnPredictor('churn_model.pkl')

    # –¢–æ–ø-15 –æ–∑–Ω–∞–∫
    importance = predictor.get_feature_importance(top_n=15)

    print("üìä –¢–æ–ø-15 –Ω–∞–π–≤–∞–∂–ª–∏–≤—ñ—à–∏—Ö –æ–∑–Ω–∞–∫:")
    for idx, row in importance.iterrows():
        direction = "üìà –ü—ñ–¥–≤–∏—â—É—î churn" if row['coefficient'] > 0 else "üìâ –ó–Ω–∏–∂—É—î churn"
        print(f"   {row['feature']:.<45} {row['coefficient']:>8.4f}  {direction}")


# ============================================================================
# MAIN
# ============================================================================

def main():
    """–ó–∞–ø—É—Å–∫ –≤—Å—ñ—Ö –ø—Ä–∏–∫–ª–∞–¥—ñ–≤"""

    print("\n" + "=" * 70)
    print("üöÄ –°–ò–°–¢–ï–ú–ê –ü–ï–†–ï–î–ë–ê–ß–ï–ù–ù–Ø CHURN - INFERENCE MODE")
    print("=" * 70)

    # –í–∏–±–µ—Ä—ñ—Ç—å –ø–æ—Ç—Ä—ñ–±–Ω–∏–π –ø—Ä–∏–∫–ª–∞–¥:

    # –ü—Ä–∏–∫–ª–∞–¥ 1: –û–¥–∏–Ω –∫–æ—Ä–∏—Å—Ç—É–≤–∞—á
    example_single_prediction()

    # –ü—Ä–∏–∫–ª–∞–¥ 2: –ö—ñ–ª—å–∫–∞ –∫–æ—Ä–∏—Å—Ç—É–≤–∞—á—ñ–≤
    # example_batch_prediction()

    # –ü—Ä–∏–∫–ª–∞–¥ 3: –ó CSV —Ñ–∞–π–ª—É
    # example_csv_prediction()

    # –ü—Ä–∏–∫–ª–∞–¥ 4: –í–∞–∂–ª–∏–≤—ñ—Å—Ç—å –æ–∑–Ω–∞–∫
    # example_feature_importance()


if __name__ == "__main__":
    main()